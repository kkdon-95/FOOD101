{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05dc3da6-fac4-49e4-be23-2473dac621f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f4ec4f-2211-4b80-b97a-823260e5752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('california_housing_train.csv')\n",
    "data_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1654765-845c-44e6-93c5-be1641e3779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17000 entries, 0 to 16999\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           17000 non-null  float64\n",
      " 1   latitude            17000 non-null  float64\n",
      " 2   housing_median_age  17000 non-null  float64\n",
      " 3   total_rooms         17000 non-null  float64\n",
      " 4   total_bedrooms      17000 non-null  float64\n",
      " 5   population          17000 non-null  float64\n",
      " 6   households          17000 non-null  float64\n",
      " 7   median_income       17000 non-null  float64\n",
      " 8   median_house_value  17000 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.2 MB\n",
      "(No of rows, No of Columns) =  (17000, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-114.31</td>\n",
       "      <td>34.19</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.4936</td>\n",
       "      <td>66900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-114.47</td>\n",
       "      <td>34.40</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1.8200</td>\n",
       "      <td>80100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-114.56</td>\n",
       "      <td>33.69</td>\n",
       "      <td>17.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.6509</td>\n",
       "      <td>85700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.64</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.1917</td>\n",
       "      <td>73400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.57</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.9250</td>\n",
       "      <td>65500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
       "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
       "2    -114.56     33.69                17.0        720.0           174.0   \n",
       "3    -114.57     33.64                14.0       1501.0           337.0   \n",
       "4    -114.57     33.57                20.0       1454.0           326.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \n",
       "0      1015.0       472.0         1.4936             66900.0  \n",
       "1      1129.0       463.0         1.8200             80100.0  \n",
       "2       333.0       117.0         1.6509             85700.0  \n",
       "3       515.0       226.0         3.1917             73400.0  \n",
       "4       624.0       262.0         1.9250             65500.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.info()\n",
    "print(\"(No of rows, No of Columns) = \",data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f0b8461-d3ba-46b2-b54c-57486002d67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17000, 8) (17000,)\n"
     ]
    }
   ],
   "source": [
    "arr = np.array(df.drop('median_house_value', axis=1)).T\n",
    "\n",
    "for i in range(len(arr)):\n",
    "  arr[i] = (arr[i]-np.mean(arr[i]))/np.std(arr[i], axis=0)\n",
    "\n",
    "y_train = np.array(df['median_house_value'])\n",
    "x_train = arr.T\n",
    "\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10afab4c-0abe-416b-96bf-1d1de7fd760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_pred,y_true):\n",
    "    squared_diff=(y_pred-y_true)**2\n",
    "    mse=squared_diff.mean()\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4575ce1f-da5d-473e-94ea-c146d646fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_prediction(x,a,b):\n",
    "    m,n=x.shape\n",
    "    y_pred=np.dot(x,a)+b\n",
    "    assert(y_pred.shape == (m,))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8189276e-3ff9-4e6c-8cf2-2ed7d82eca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x,a,b,y_true):\n",
    "    m,n=x.shape\n",
    "    yp=np.dot(x,a)+b\n",
    "    diff=yp-y_true\n",
    "    da=(2/m)*np.dot(diff,x)\n",
    "    db=(2/m)*np.sum(diff)\n",
    "    assert(da.shape ==(n,))\n",
    "    return (da,db)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f64e7f6-a8f2-4a28-b7ce-49ac66bfad11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69da3c71-141b-40fe-9565-609cd6964384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x,y_true,learning_rate=0.01,epochs = 10):\n",
    "    m,n = x.shape\n",
    "    loss_mse = []                                 \n",
    "    a = np.random.normal(0, 0.5, size = (n,)) * np.sqrt(2/n)     \n",
    "    b = 0\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        da,db=gradient(x,a,b,y_true)\n",
    "        a=a-learning_rate*da\n",
    "        b=b-learning_rate*db\n",
    "        yp=np.dot(x,a)+b\n",
    "        Loss=loss(yp,y_true)\n",
    "        loss_mse.append(loss)\n",
    "        print(\"Epoch \",i+1,\" Completed!\",\"loss = \",Loss) \n",
    "\n",
    "\n",
    "    \n",
    "    print(\"Training completed!!\")\n",
    "    assert(a.shape==(n,))\n",
    "    return (loss_mse,a,b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f92fcb6-976c-44e1-9f5a-0eff194c6984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1  Completed! loss =  52490455426.39653\n",
      "Epoch  2  Completed! loss =  48866254681.53561\n",
      "Epoch  3  Completed! loss =  45527310861.4208\n",
      "Epoch  4  Completed! loss =  42450637928.01794\n",
      "Epoch  5  Completed! loss =  39615227680.61193\n",
      "Epoch  6  Completed! loss =  37001845529.85236\n",
      "Epoch  7  Completed! loss =  34592856225.47412\n",
      "Epoch  8  Completed! loss =  32372073200.413696\n",
      "Epoch  9  Completed! loss =  30324626837.09453\n",
      "Epoch  10  Completed! loss =  28436848145.86276\n",
      "Epoch  11  Completed! loss =  26696165202.0058\n",
      "Epoch  12  Completed! loss =  25091010309.867027\n",
      "Epoch  13  Completed! loss =  23610736316.831196\n",
      "Epoch  14  Completed! loss =  22245540833.84101\n",
      "Epoch  15  Completed! loss =  20986397366.45751\n",
      "Epoch  16  Completed! loss =  19824992545.451283\n",
      "Epoch  17  Completed! loss =  18753668785.76446\n",
      "Epoch  18  Completed! loss =  17765371809.75544\n",
      "Epoch  19  Completed! loss =  16853602553.768198\n",
      "Epoch  20  Completed! loss =  16012373042.59594\n",
      "Epoch  21  Completed! loss =  15236165868.893728\n",
      "Epoch  22  Completed! loss =  14519896957.32384\n",
      "Epoch  23  Completed! loss =  13858881328.568989\n",
      "Epoch  24  Completed! loss =  13248801608.050636\n",
      "Epoch  25  Completed! loss =  12685679049.505322\n",
      "Epoch  26  Completed! loss =  12165846865.429462\n",
      "Epoch  27  Completed! loss =  11685925675.491264\n",
      "Epoch  28  Completed! loss =  11242800900.84196\n",
      "Epoch  29  Completed! loss =  10833601947.227285\n",
      "Epoch  30  Completed! loss =  10455683033.202465\n",
      "Epoch  31  Completed! loss =  10106605531.821585\n",
      "Epoch  32  Completed! loss =  9784121705.087994\n",
      "Epoch  33  Completed! loss =  9486159720.362803\n",
      "Epoch  34  Completed! loss =  9210809846.9523\n",
      "Epoch  35  Completed! loss =  8956311739.33149\n",
      "Epoch  36  Completed! loss =  8721042720.992\n",
      "Epoch  37  Completed! loss =  8503506989.799392\n",
      "Epoch  38  Completed! loss =  8302325672.067754\n",
      "Epoch  39  Completed! loss =  8116227658.36191\n",
      "Epoch  40  Completed! loss =  7944041159.366038\n",
      "Epoch  41  Completed! loss =  7784685925.053564\n",
      "Epoch  42  Completed! loss =  7637166074.894235\n",
      "Epoch  43  Completed! loss =  7500563490.973405\n",
      "Epoch  44  Completed! loss =  7374031729.706243\n",
      "Epoch  45  Completed! loss =  7256790411.332905\n",
      "Epoch  46  Completed! loss =  7148120049.605084\n",
      "Epoch  47  Completed! loss =  7047357287.041844\n",
      "Epoch  48  Completed! loss =  6953890503.864677\n",
      "Epoch  49  Completed! loss =  6867155771.236831\n",
      "Epoch  50  Completed! loss =  6786633121.747797\n",
      "Epoch  51  Completed! loss =  6711843112.216208\n",
      "Epoch  52  Completed! loss =  6642343655.84819\n",
      "Epoch  53  Completed! loss =  6577727102.596527\n",
      "Epoch  54  Completed! loss =  6517617548.231594\n",
      "Epoch  55  Completed! loss =  6461668354.168904\n",
      "Epoch  56  Completed! loss =  6409559861.510982\n",
      "Epoch  57  Completed! loss =  6360997284.0626335\n",
      "Epoch  58  Completed! loss =  6315708766.277384\n",
      "Epoch  59  Completed! loss =  6273443593.196984\n",
      "Epoch  60  Completed! loss =  6233970540.46305\n",
      "Epoch  61  Completed! loss =  6197076353.416833\n",
      "Epoch  62  Completed! loss =  6162564345.166279\n",
      "Epoch  63  Completed! loss =  6130253104.294693\n",
      "Epoch  64  Completed! loss =  6099975303.617843\n",
      "Epoch  65  Completed! loss =  6071576602.071265\n",
      "Epoch  66  Completed! loss =  6044914632.431223\n",
      "Epoch  67  Completed! loss =  6019858068.145646\n",
      "Epoch  68  Completed! loss =  5996285763.07915\n",
      "Epoch  69  Completed! loss =  5974085958.462431\n",
      "Epoch  70  Completed! loss =  5953155551.784416\n",
      "Epoch  71  Completed! loss =  5933399422.778282\n",
      "Epoch  72  Completed! loss =  5914729812.032826\n",
      "Epoch  73  Completed! loss =  5897065748.111113\n",
      "Epoch  74  Completed! loss =  5880332519.381204\n",
      "Epoch  75  Completed! loss =  5864461187.061373\n",
      "Epoch  76  Completed! loss =  5849388136.256313\n",
      "Epoch  77  Completed! loss =  5835054662.013493\n",
      "Epoch  78  Completed! loss =  5821406587.661666\n",
      "Epoch  79  Completed! loss =  5808393912.907964\n",
      "Epoch  80  Completed! loss =  5795970489.367759\n",
      "Epoch  81  Completed! loss =  5784093721.383605\n",
      "Epoch  82  Completed! loss =  5772724290.157452\n",
      "Epoch  83  Completed! loss =  5761825899.375004\n",
      "Epoch  84  Completed! loss =  5751365040.643695\n",
      "Epoch  85  Completed! loss =  5741310777.197074\n",
      "Epoch  86  Completed! loss =  5731634544.439522\n",
      "Epoch  87  Completed! loss =  5722309966.016794\n",
      "Epoch  88  Completed! loss =  5713312684.200678\n",
      "Epoch  89  Completed! loss =  5704620203.47088\n",
      "Epoch  90  Completed! loss =  5696211746.264586\n",
      "Epoch  91  Completed! loss =  5688068119.94462\n",
      "Epoch  92  Completed! loss =  5680171594.1113405\n",
      "Epoch  93  Completed! loss =  5672505787.451802\n",
      "Epoch  94  Completed! loss =  5665055563.382724\n",
      "Epoch  95  Completed! loss =  5657806933.801878\n",
      "Epoch  96  Completed! loss =  5650746970.316118\n",
      "Epoch  97  Completed! loss =  5643863722.363538\n",
      "Epoch  98  Completed! loss =  5637146141.692782\n",
      "Epoch  99  Completed! loss =  5630584012.704477\n",
      "Epoch  100  Completed! loss =  5624167888.198354\n",
      "Epoch  101  Completed! loss =  5617889030.105254\n",
      "Epoch  102  Completed! loss =  5611739354.816144\n",
      "Epoch  103  Completed! loss =  5605711382.750363\n",
      "Epoch  104  Completed! loss =  5599798191.833404\n",
      "Epoch  105  Completed! loss =  5593993374.580132\n",
      "Epoch  106  Completed! loss =  5588290998.5030985\n",
      "Epoch  107  Completed! loss =  5582685569.587478\n",
      "Epoch  108  Completed! loss =  5577171998.5942545\n",
      "Epoch  109  Completed! loss =  5571745569.971928\n",
      "Epoch  110  Completed! loss =  5566401913.17406\n",
      "Epoch  111  Completed! loss =  5561136976.195844\n",
      "Epoch  112  Completed! loss =  5555947001.157348\n",
      "Epoch  113  Completed! loss =  5550828501.774591\n",
      "Epoch  114  Completed! loss =  5545778242.571908\n",
      "Epoch  115  Completed! loss =  5540793219.700493\n",
      "Epoch  116  Completed! loss =  5535870643.23854\n",
      "Epoch  117  Completed! loss =  5531007920.858064\n",
      "Epoch  118  Completed! loss =  5526202642.752448\n",
      "Epoch  119  Completed! loss =  5521452567.7269745\n",
      "Epoch  120  Completed! loss =  5516755610.362239\n",
      "Epoch  121  Completed! loss =  5512109829.167321\n",
      "Epoch  122  Completed! loss =  5507513415.646026\n",
      "Epoch  123  Completed! loss =  5502964684.205544\n",
      "Epoch  124  Completed! loss =  5498462062.842271\n",
      "Epoch  125  Completed! loss =  5494004084.544674\n",
      "Epoch  126  Completed! loss =  5489589379.35771\n",
      "Epoch  127  Completed! loss =  5485216667.057639\n",
      "Epoch  128  Completed! loss =  5480884750.39003\n",
      "Epoch  129  Completed! loss =  5476592508.827426\n",
      "Epoch  130  Completed! loss =  5472338892.8064995\n",
      "Epoch  131  Completed! loss =  5468122918.407683\n",
      "Epoch  132  Completed! loss =  5463943662.443064\n",
      "Epoch  133  Completed! loss =  5459800257.921047\n",
      "Epoch  134  Completed! loss =  5455691889.858711\n",
      "Epoch  135  Completed! loss =  5451617791.415005\n",
      "Epoch  136  Completed! loss =  5447577240.320049\n",
      "Epoch  137  Completed! loss =  5443569555.577735\n",
      "Epoch  138  Completed! loss =  5439594094.420493\n",
      "Epoch  139  Completed! loss =  5435650249.496877\n",
      "Epoch  140  Completed! loss =  5431737446.273956\n",
      "Epoch  141  Completed! loss =  5427855140.63803\n",
      "Epoch  142  Completed! loss =  5424002816.678376\n",
      "Epoch  143  Completed! loss =  5420179984.63992\n",
      "Epoch  144  Completed! loss =  5416386179.031907\n",
      "Epoch  145  Completed! loss =  5412620956.880495\n",
      "Epoch  146  Completed! loss =  5408883896.1142645\n",
      "Epoch  147  Completed! loss =  5405174594.072404\n",
      "Epoch  148  Completed! loss =  5401492666.126173\n",
      "Epoch  149  Completed! loss =  5397837744.404917\n",
      "Epoch  150  Completed! loss =  5394209476.618632\n",
      "Epoch  151  Completed! loss =  5390607524.969669\n",
      "Epoch  152  Completed! loss =  5387031565.146729\n",
      "Epoch  153  Completed! loss =  5383481285.394867\n",
      "Epoch  154  Completed! loss =  5379956385.655651\n",
      "Epoch  155  Completed! loss =  5376456576.772131\n",
      "Epoch  156  Completed! loss =  5372981579.75365\n",
      "Epoch  157  Completed! loss =  5369531125.095896\n",
      "Epoch  158  Completed! loss =  5366104952.152013\n",
      "Epoch  159  Completed! loss =  5362702808.550826\n",
      "Epoch  160  Completed! loss =  5359324449.658613\n",
      "Epoch  161  Completed! loss =  5355969638.081076\n",
      "Epoch  162  Completed! loss =  5352638143.202461\n",
      "Epoch  163  Completed! loss =  5349329740.758988\n",
      "Epoch  164  Completed! loss =  5346044212.443961\n",
      "Epoch  165  Completed! loss =  5342781345.542168\n",
      "Epoch  166  Completed! loss =  5339540932.591327\n",
      "Epoch  167  Completed! loss =  5336322771.068525\n",
      "Epoch  168  Completed! loss =  5333126663.099748\n",
      "Epoch  169  Completed! loss =  5329952415.19073\n",
      "Epoch  170  Completed! loss =  5326799837.977553\n",
      "Epoch  171  Completed! loss =  5323668745.995434\n",
      "Epoch  172  Completed! loss =  5320558957.464356\n",
      "Epoch  173  Completed! loss =  5317470294.090278\n",
      "Epoch  174  Completed! loss =  5314402580.880704\n",
      "Epoch  175  Completed! loss =  5311355645.973569\n",
      "Epoch  176  Completed! loss =  5308329320.478395\n",
      "Epoch  177  Completed! loss =  5305323438.328827\n",
      "Epoch  178  Completed! loss =  5302337836.145658\n",
      "Epoch  179  Completed! loss =  5299372353.109572\n",
      "Epoch  180  Completed! loss =  5296426830.842877\n",
      "Epoch  181  Completed! loss =  5293501113.299525\n",
      "Epoch  182  Completed! loss =  5290595046.662814\n",
      "Epoch  183  Completed! loss =  5287708479.250221\n",
      "Epoch  184  Completed! loss =  5284841261.424773\n",
      "Epoch  185  Completed! loss =  5281993245.512504\n",
      "Epoch  186  Completed! loss =  5279164285.725552\n",
      "Epoch  187  Completed! loss =  5276354238.090445\n",
      "Epoch  188  Completed! loss =  5273562960.381202\n",
      "Epoch  189  Completed! loss =  5270790312.056901\n",
      "Epoch  190  Completed! loss =  5268036154.203358\n",
      "Epoch  191  Completed! loss =  5265300349.478631\n",
      "Epoch  192  Completed! loss =  5262582762.06207\n",
      "Epoch  193  Completed! loss =  5259883257.606615\n",
      "Epoch  194  Completed! loss =  5257201703.194152\n",
      "Epoch  195  Completed! loss =  5254537967.293654\n",
      "Epoch  196  Completed! loss =  5251891919.721949\n",
      "Epoch  197  Completed! loss =  5249263431.606865\n",
      "Epoch  198  Completed! loss =  5246652375.352638\n",
      "Epoch  199  Completed! loss =  5244058624.60738\n",
      "Epoch  200  Completed! loss =  5241482054.232452\n",
      "Training completed!!\n",
      "[<function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>, <function loss at 0x12f56ccc0>]\n"
     ]
    }
   ],
   "source": [
    "epochs = 200             \n",
    "learn_rate = 0.02         \n",
    "\n",
    "train_loss,a,b = gradient_descent(x_train, y_train, learn_rate, epochs)\n",
    "print(train_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c86a183-682d-42ec-8fcb-7364edc5a807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test data =  5241482054.232452\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'function'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m test_loss \u001b[38;5;241m=\u001b[39mdiff\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss on test data = \u001b[39m\u001b[38;5;124m\"\u001b[39m,test_loss)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/food101/lib/python3.13/site-packages/matplotlib/pyplot.py:3794\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3786\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3788\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3793\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3795\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3798\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3799\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3800\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/food101/lib/python3.13/site-packages/matplotlib/axes/_axes.py:1781\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m-> 1781\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scalex:\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_autoscale_view(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/food101/lib/python3.13/site-packages/matplotlib/axes/_base.py:2339\u001b[0m, in \u001b[0;36m_AxesBase.add_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   2336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2337\u001b[0m     line\u001b[38;5;241m.\u001b[39mset_clip_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch)\n\u001b[0;32m-> 2339\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_line_limits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line\u001b[38;5;241m.\u001b[39mget_label():\n\u001b[1;32m   2341\u001b[0m     line\u001b[38;5;241m.\u001b[39mset_label(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_child\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/food101/lib/python3.13/site-packages/matplotlib/axes/_base.py:2362\u001b[0m, in \u001b[0;36m_AxesBase._update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   2358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_line_limits\u001b[39m(\u001b[38;5;28mself\u001b[39m, line):\n\u001b[1;32m   2359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2360\u001b[0m \u001b[38;5;124;03m    Figures out the data limit of the given line, updating self.dataLim.\u001b[39;00m\n\u001b[1;32m   2361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2362\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2363\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mvertices\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2364\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/food101/lib/python3.13/site-packages/matplotlib/lines.py:1037\u001b[0m, in \u001b[0;36mLine2D.get_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the `~matplotlib.path.Path` associated with this line.\"\"\"\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invalidy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invalidx:\n\u001b[0;32m-> 1037\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path\n",
      "File \u001b[0;32m/opt/miniconda3/envs/food101/lib/python3.13/site-packages/matplotlib/lines.py:679\u001b[0m, in \u001b[0;36mLine2D.recache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m always \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invalidy:\n\u001b[1;32m    678\u001b[0m     yconv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_yunits(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_yorig)\n\u001b[0;32m--> 679\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43m_to_unmasked_float_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43myconv\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    681\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y\n",
      "File \u001b[0;32m/opt/miniconda3/envs/food101/lib/python3.13/site-packages/matplotlib/cbook.py:1398\u001b[0m, in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39masarray(x, \u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39mfilled(np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'function'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"california_housing_train.csv\")\n",
    "\n",
    "arr = np.array(test_df.drop('median_house_value', axis=1)).T\n",
    "\n",
    "for i in range(len(arr)):\n",
    "  arr[i] = (arr[i]-np.mean(arr[i]))/np.std(arr[i], axis=0)\n",
    "\n",
    "y_test = np.array(test_df['median_house_value'])                                                                                                            # extract the price column from data\n",
    "\n",
    "x_test = arr.T\n",
    "y_pred=np.dot(x_test,a)+b\n",
    "diff=(y_pred-y_test)**2\n",
    "test_loss =diff.mean()\n",
    "\n",
    "print(\"Loss on test data = \",test_loss)\n",
    "plt.plot([i for i in range(epochs)], train_loss)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9158831-53a9-47a6-84fe-f99e06564d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (food101)",
   "language": "python",
   "name": "food101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
